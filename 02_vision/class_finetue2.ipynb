{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy\n",
    "import matplotlib\n",
    "import os\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据变换的函数\n",
    "data_transform = {'train': transforms.Compose([\n",
    "                transforms.RandomSizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "                'val': transforms.Compose(\n",
    "                    [transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "                }\n",
    "folder_path = \"./data/beef\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(folder_path, x), data_transform[x]) for x in ['train','val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                batch_size=4,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=4)\n",
    "                        for x in ['train','val']}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset_size = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 122, 122]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 122, 122]             128\n",
      "              ReLU-3         [-1, 64, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 64, 61, 61]               0\n",
      "            Conv2d-5           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 61, 61]             128\n",
      "              ReLU-7           [-1, 64, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
      "             ReLU-10           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-11           [-1, 64, 61, 61]               0\n",
      "           Conv2d-12           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 61, 61]             128\n",
      "             ReLU-14           [-1, 64, 61, 61]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-18           [-1, 64, 61, 61]               0\n",
      "           Conv2d-19          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 31, 31]             256\n",
      "             ReLU-21          [-1, 128, 31, 31]               0\n",
      "           Conv2d-22          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 31, 31]             256\n",
      "           Conv2d-24          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 31, 31]             256\n",
      "             ReLU-26          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-27          [-1, 128, 31, 31]               0\n",
      "           Conv2d-28          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 31, 31]             256\n",
      "             ReLU-30          [-1, 128, 31, 31]               0\n",
      "           Conv2d-31          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 31, 31]             256\n",
      "             ReLU-33          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-34          [-1, 128, 31, 31]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 76.08\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 121.36\n",
      "----------------------------------------------------------------\n",
      "1000\n",
      "512\n",
      "2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SGD' object has no attribute 'SGD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12580/2310936774.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0moptim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SGD' object has no attribute 'SGD'"
     ]
    }
   ],
   "source": [
    "# 创建模型\n",
    "# 加载预训练的模型\n",
    "model = models.resnet18(pretrained=True)\n",
    "# 查看模型的状态\n",
    "# print(model)\n",
    "summary(model,(3,244,244))\n",
    "\n",
    "# 获得模型中fc 层\n",
    "model_fc_features = model.fc.in_features\n",
    "print(model.fc.out_features)\n",
    "print(model_fc_features)\n",
    "model.fc = nn.Linear(model_fc_features,2)\n",
    "\n",
    "print(model.fc.out_features)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optim = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "lr_scheduler = lr_scheduler.StepLR(optim, step_size=7, gamma=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=15):\n",
    "    since = time.time()\n",
    "\n",
    "    #获得模型的参数\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epock{epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        for phase in ['train','val']:\n",
    "            # 设置模型是是训练还是验证阶段\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # 加载数据，并将数据放入cpu或者GPU中\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 对梯度清零\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #是否做梯度运算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 前向传播\n",
    "                    outputs = model(inputs)\n",
    "                    # 获得推理的结果，这里是logistic\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # 计算损失值\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 在训练阶段需要反向传播，并更新梯度值\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 计算一个batch的损失值和准确率\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)  \n",
    "\n",
    "            # 更新学习率\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # 计算损失值和准确率\n",
    "            epoch_loss = running_loss / dataset_size[phase] \n",
    "            epoch_acc = running_corrects.double() / dataset_size[phase] \n",
    "\n",
    "            print('{} Loos: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc\n",
    "            ))  \n",
    "\n",
    "            # 将最好的模型进行保存\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))  \n",
    "\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # 加载模型\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epock0/24\n",
      "--------------------\n",
      "train Loos: 0.7162 Acc: 0.5082\n",
      "val Loos: 0.7179 Acc: 0.5229\n",
      "Epock1/24\n",
      "--------------------\n",
      "train Loos: 0.7112 Acc: 0.5492\n",
      "val Loos: 0.7000 Acc: 0.5294\n",
      "Epock2/24\n",
      "--------------------\n",
      "train Loos: 0.7082 Acc: 0.4918\n",
      "val Loos: 0.7173 Acc: 0.5229\n",
      "Epock3/24\n",
      "--------------------\n",
      "train Loos: 0.7004 Acc: 0.5369\n",
      "val Loos: 0.6989 Acc: 0.5294\n",
      "Epock4/24\n",
      "--------------------\n",
      "train Loos: 0.7096 Acc: 0.5451\n",
      "val Loos: 0.7019 Acc: 0.5229\n",
      "Epock5/24\n",
      "--------------------\n",
      "train Loos: 0.6875 Acc: 0.5451\n",
      "val Loos: 0.7103 Acc: 0.5425\n",
      "Epock6/24\n",
      "--------------------\n",
      "train Loos: 0.7056 Acc: 0.5328\n",
      "val Loos: 0.7110 Acc: 0.5033\n",
      "Epock7/24\n",
      "--------------------\n",
      "train Loos: 0.6874 Acc: 0.5451\n",
      "val Loos: 0.7195 Acc: 0.5294\n",
      "Epock8/24\n",
      "--------------------\n",
      "train Loos: 0.6931 Acc: 0.5451\n",
      "val Loos: 0.7233 Acc: 0.5229\n",
      "Epock9/24\n",
      "--------------------\n",
      "train Loos: 0.7204 Acc: 0.4959\n",
      "val Loos: 0.7179 Acc: 0.4967\n",
      "Epock10/24\n",
      "--------------------\n",
      "train Loos: 0.6940 Acc: 0.5697\n",
      "val Loos: 0.7240 Acc: 0.5098\n",
      "Epock11/24\n",
      "--------------------\n",
      "train Loos: 0.7265 Acc: 0.5164\n",
      "val Loos: 0.7008 Acc: 0.5425\n",
      "Epock12/24\n",
      "--------------------\n",
      "train Loos: 0.6973 Acc: 0.5328\n",
      "val Loos: 0.7086 Acc: 0.5163\n",
      "Epock13/24\n",
      "--------------------\n",
      "train Loos: 0.6904 Acc: 0.5574\n",
      "val Loos: 0.7086 Acc: 0.5098\n",
      "Epock14/24\n",
      "--------------------\n",
      "train Loos: 0.7098 Acc: 0.5205\n",
      "val Loos: 0.7088 Acc: 0.5229\n",
      "Epock15/24\n",
      "--------------------\n",
      "train Loos: 0.6918 Acc: 0.5615\n",
      "val Loos: 0.7108 Acc: 0.4967\n",
      "Epock16/24\n",
      "--------------------\n",
      "train Loos: 0.6933 Acc: 0.5533\n",
      "val Loos: 0.7336 Acc: 0.4967\n",
      "Epock17/24\n",
      "--------------------\n",
      "train Loos: 0.7020 Acc: 0.5492\n",
      "val Loos: 0.7111 Acc: 0.5098\n",
      "Epock18/24\n",
      "--------------------\n",
      "train Loos: 0.6964 Acc: 0.5492\n",
      "val Loos: 0.7147 Acc: 0.5098\n",
      "Epock19/24\n",
      "--------------------\n",
      "train Loos: 0.7114 Acc: 0.5205\n",
      "val Loos: 0.6968 Acc: 0.5359\n",
      "Epock20/24\n",
      "--------------------\n",
      "train Loos: 0.7030 Acc: 0.5287\n",
      "val Loos: 0.7010 Acc: 0.5294\n",
      "Epock21/24\n",
      "--------------------\n",
      "train Loos: 0.6871 Acc: 0.5287\n",
      "val Loos: 0.7281 Acc: 0.5098\n",
      "Epock22/24\n",
      "--------------------\n",
      "train Loos: 0.7112 Acc: 0.5164\n",
      "val Loos: 0.7176 Acc: 0.5229\n",
      "Epock23/24\n",
      "--------------------\n",
      "train Loos: 0.7075 Acc: 0.5410\n",
      "val Loos: 0.7062 Acc: 0.5294\n",
      "Epock24/24\n",
      "--------------------\n",
      "train Loos: 0.7114 Acc: 0.5000\n",
      "val Loos: 0.7212 Acc: 0.5229\n",
      "Training complete in 14m 41s\n",
      "Best val Acc: 0.542484\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12580/337355967.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_ft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12580/202126014.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# 加载模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model_wts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1453\u001b[0m         \u001b[1;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_metadata'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1455\u001b[1;33m         \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1456\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m             \u001b[1;31m# mypy isn't aware that \"_metadata\" exists in state_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model,criterion,optim,lr_scheduler, num_epochs=25)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ba52228318ac7a49b387b661d7c5b5da191fb3537bd08c26009413472b57ea6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
