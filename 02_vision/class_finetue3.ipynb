{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import optim\n",
    "from torch.utils.data import dataloader\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "\n",
    "# 定义transform 函数\n",
    "data_transform = {'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])}\n",
    "\n",
    "# 通过torchvision的datasets 导入图片，加载成torch的dataset格式\n",
    "img_path = \"./data/beef\"\n",
    "img_datasets = {x: datasets.ImageFolder(os.path.join(img_path,x),data_transform[x]) for x in ['train','val']}\n",
    "# 加载成dataloader对图片进行batch 打包成一个迭代器\n",
    "dataloaders = {x: dataloader.DataLoader(img_datasets[x],\n",
    "                                        batch_size=4,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=4) \n",
    "                                        for x in ['train', 'val']}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_size = {x: len(img_datasets[x]) for x in ['train', 'val']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练通用函数\n",
    "def train_model(model, creterion, optimizer, scheduler, epoch_num=10):\n",
    "    \n",
    "    since = time.time()\n",
    "    # 模型参数的保存\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        print(\"*\"*20)\n",
    "        print(\"Epoch {}/{}  training:\".format(epoch + 1, epoch_num))\n",
    "\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            # 设置模型的模式：训练or验证\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_acc = 0\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                # 设置数据到指定的硬件设备：cpu or gpu\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                # 梯度参数置零\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 获得模型的预测值的输出，这里好像没有用softmax, 因为是2为输出\n",
    "                    outputs = model(inputs)\n",
    "                    # 查找每一行输入中最大值的那个\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # 用交叉熵计算损失值\n",
    "                    loss = creterion(outputs, targets)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        # 计算反向传播的梯度值值\n",
    "                        loss.backward()\n",
    "                        # 更新权重参数\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 计算一个batch的损失函数\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_acc += torch.sum(preds == targets)\n",
    "            \n",
    "            # 更新学习率\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            # 计算每个epoch的损失值与准确率\n",
    "            epoch_loss = running_loss / dataset_size[phase]\n",
    "            epoch_acc = running_acc / dataset_size[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc\n",
    "            ))\n",
    "\n",
    "            if phase == 'val':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与训练模型的设置\n",
    "model_tf = models.resnet18(pretrained=True)\n",
    "\n",
    "# 设置模型为\n",
    "for param in model_tf.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_fts = model_tf.fc.in_features\n",
    "\n",
    "model_tf.fc = torch.nn.Linear(num_fts, 2)\n",
    "\n",
    "model_tf.to(device)\n",
    "\n",
    "creterion_ft = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_tf.fc.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "scheduler_ft = lr_scheduler.StepLR(optimizer=optimizer_ft, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Epoch 1/10  training:\n",
      "train Loss: 0.4156 Acc: 0.8279\n",
      "val Loss: 0.2847 Acc: 0.9346\n",
      "********************\n",
      "Epoch 2/10  training:\n",
      "train Loss: 0.4527 Acc: 0.7869\n",
      "val Loss: 0.2729 Acc: 0.9150\n",
      "********************\n",
      "Epoch 3/10  training:\n",
      "train Loss: 0.4102 Acc: 0.8484\n",
      "val Loss: 0.2823 Acc: 0.9216\n",
      "********************\n",
      "Epoch 4/10  training:\n",
      "train Loss: 0.3963 Acc: 0.8525\n",
      "val Loss: 0.2783 Acc: 0.9281\n",
      "********************\n",
      "Epoch 5/10  training:\n",
      "train Loss: 0.4730 Acc: 0.7828\n",
      "val Loss: 0.2763 Acc: 0.9216\n",
      "********************\n",
      "Epoch 6/10  training:\n",
      "train Loss: 0.4580 Acc: 0.7951\n",
      "val Loss: 0.2813 Acc: 0.9216\n",
      "********************\n",
      "Epoch 7/10  training:\n",
      "train Loss: 0.4527 Acc: 0.7951\n",
      "val Loss: 0.2663 Acc: 0.9281\n",
      "********************\n",
      "Epoch 8/10  training:\n",
      "train Loss: 0.4151 Acc: 0.8279\n",
      "val Loss: 0.2764 Acc: 0.9281\n",
      "********************\n",
      "Epoch 9/10  training:\n",
      "train Loss: 0.4080 Acc: 0.8443\n",
      "val Loss: 0.2859 Acc: 0.9281\n",
      "********************\n",
      "Epoch 10/10  training:\n",
      "train Loss: 0.4004 Acc: 0.8361\n",
      "val Loss: 0.2779 Acc: 0.9216\n",
      "Training complete in 3m 24s\n",
      "Best val Acc: 0.934641\n"
     ]
    }
   ],
   "source": [
    "model_trained = train_model(model_tf, creterion_ft, optimizer_ft, scheduler_ft)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ba52228318ac7a49b387b661d7c5b5da191fb3537bd08c26009413472b57ea6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
