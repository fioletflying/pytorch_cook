{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data,batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数定义\n",
    "- epoch: 迭代数据集的次数\n",
    "- batch_size: 更新数据之前需要传入样本数量\n",
    "- learning_rate： 每个批次/epoch 更新模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化循环\n",
    "\n",
    "- 训练循环：循环访问训练集并且尝试收敛到最佳的参数\n",
    "- 验证/测试循环：循环访问测试数据集，用来检查模型的精度是否在提高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "损失函数用来表征模型训练结果与正确值之间的差距，所以模型训练的主要目的就是最小化损失函数的值。创建的损失函数：\n",
    "- 回归任务： nn.MSELoss (均方差)\n",
    "- 分类任务   nn.NLLLoss (负对数似然)\n",
    "- 交叉熵： nn.CrossEntropyLoss 结合了nn.LogSoftmax 和 nn.NLLLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "优化器就是调整模型的参数使得减少每个训练步骤中的模型损失值的过程。优化器主要有：\n",
    "- SGD\n",
    "- ADAM\n",
    "- RMSProp\n",
    "\n",
    "训练循环中优化三个步骤：\n",
    "- 调用重置模型参数的梯度值，每次迭代都显式将其归零：optimizer.zero_grad()\n",
    "- 调用反向传播预测损失值：loss.backward()\n",
    "- 通过梯度调整参数： optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        # 计算预测值与损失值\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        #反向传播三部曲\n",
    "        # 将参数的梯度值重置为零，因为Pytorch 中的参数的梯度每次计算都会累加\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播：就是由损失函数反向传播计算出来的每个参数的梯度值，并且保存在相应的参数下面\n",
    "        loss.backward()\n",
    "        # 通过梯度值调整更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印相关的参数\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in  dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epock 1\n",
      "-----------------------\n",
      "loss: 2.169856  [    0/60000]\n",
      "loss: 2.158634  [ 6400/60000]\n",
      "loss: 2.097372  [12800/60000]\n",
      "loss: 2.115595  [19200/60000]\n",
      "loss: 2.066057  [25600/60000]\n",
      "loss: 2.016772  [32000/60000]\n",
      "loss: 2.043740  [38400/60000]\n",
      "loss: 1.963690  [44800/60000]\n",
      "loss: 1.988068  [51200/60000]\n",
      "loss: 1.898363  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 1.892623 \n",
      "\n",
      "Epock 2\n",
      "-----------------------\n",
      "loss: 1.923162  [    0/60000]\n",
      "loss: 1.893267  [ 6400/60000]\n",
      "loss: 1.769507  [12800/60000]\n",
      "loss: 1.813618  [19200/60000]\n",
      "loss: 1.699503  [25600/60000]\n",
      "loss: 1.662534  [32000/60000]\n",
      "loss: 1.677342  [38400/60000]\n",
      "loss: 1.578223  [44800/60000]\n",
      "loss: 1.615656  [51200/60000]\n",
      "loss: 1.495543  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 1.511939 \n",
      "\n",
      "Epock 3\n",
      "-----------------------\n",
      "loss: 1.570234  [    0/60000]\n",
      "loss: 1.541874  [ 6400/60000]\n",
      "loss: 1.385552  [12800/60000]\n",
      "loss: 1.460296  [19200/60000]\n",
      "loss: 1.336903  [25600/60000]\n",
      "loss: 1.345981  [32000/60000]\n",
      "loss: 1.348247  [38400/60000]\n",
      "loss: 1.275961  [44800/60000]\n",
      "loss: 1.321327  [51200/60000]\n",
      "loss: 1.215369  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 1.237844 \n",
      "\n",
      "Epock 4\n",
      "-----------------------\n",
      "loss: 1.303763  [    0/60000]\n",
      "loss: 1.295989  [ 6400/60000]\n",
      "loss: 1.124470  [12800/60000]\n",
      "loss: 1.236739  [19200/60000]\n",
      "loss: 1.106343  [25600/60000]\n",
      "loss: 1.143798  [32000/60000]\n",
      "loss: 1.155178  [38400/60000]\n",
      "loss: 1.095172  [44800/60000]\n",
      "loss: 1.145830  [51200/60000]\n",
      "loss: 1.058172  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.074175 \n",
      "\n",
      "Epock 5\n",
      "-----------------------\n",
      "loss: 1.132067  [    0/60000]\n",
      "loss: 1.147193  [ 6400/60000]\n",
      "loss: 0.958216  [12800/60000]\n",
      "loss: 1.102446  [19200/60000]\n",
      "loss: 0.967364  [25600/60000]\n",
      "loss: 1.010879  [32000/60000]\n",
      "loss: 1.039894  [38400/60000]\n",
      "loss: 0.983383  [44800/60000]\n",
      "loss: 1.034327  [51200/60000]\n",
      "loss: 0.961540  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.970554 \n",
      "\n",
      "Epock 6\n",
      "-----------------------\n",
      "loss: 1.014396  [    0/60000]\n",
      "loss: 1.052876  [ 6400/60000]\n",
      "loss: 0.845789  [12800/60000]\n",
      "loss: 1.014282  [19200/60000]\n",
      "loss: 0.879543  [25600/60000]\n",
      "loss: 0.917426  [32000/60000]\n",
      "loss: 0.965702  [38400/60000]\n",
      "loss: 0.911108  [44800/60000]\n",
      "loss: 0.957816  [51200/60000]\n",
      "loss: 0.896330  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.899894 \n",
      "\n",
      "Epock 7\n",
      "-----------------------\n",
      "loss: 0.928275  [    0/60000]\n",
      "loss: 0.987285  [ 6400/60000]\n",
      "loss: 0.765118  [12800/60000]\n",
      "loss: 0.951245  [19200/60000]\n",
      "loss: 0.820674  [25600/60000]\n",
      "loss: 0.848577  [32000/60000]\n",
      "loss: 0.913854  [38400/60000]\n",
      "loss: 0.862334  [44800/60000]\n",
      "loss: 0.902539  [51200/60000]\n",
      "loss: 0.848592  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.848614 \n",
      "\n",
      "Epock 8\n",
      "-----------------------\n",
      "loss: 0.861852  [    0/60000]\n",
      "loss: 0.937664  [ 6400/60000]\n",
      "loss: 0.704412  [12800/60000]\n",
      "loss: 0.903449  [19200/60000]\n",
      "loss: 0.778664  [25600/60000]\n",
      "loss: 0.796855  [32000/60000]\n",
      "loss: 0.874489  [38400/60000]\n",
      "loss: 0.828086  [44800/60000]\n",
      "loss: 0.861002  [51200/60000]\n",
      "loss: 0.811752  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.809543 \n",
      "\n",
      "Epock 9\n",
      "-----------------------\n",
      "loss: 0.808820  [    0/60000]\n",
      "loss: 0.897669  [ 6400/60000]\n",
      "loss: 0.657139  [12800/60000]\n",
      "loss: 0.865961  [19200/60000]\n",
      "loss: 0.747159  [25600/60000]\n",
      "loss: 0.757170  [32000/60000]\n",
      "loss: 0.842432  [38400/60000]\n",
      "loss: 0.802641  [44800/60000]\n",
      "loss: 0.828549  [51200/60000]\n",
      "loss: 0.782206  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.778376 \n",
      "\n",
      "Epock 10\n",
      "-----------------------\n",
      "loss: 0.765222  [    0/60000]\n",
      "loss: 0.863438  [ 6400/60000]\n",
      "loss: 0.619107  [12800/60000]\n",
      "loss: 0.835677  [19200/60000]\n",
      "loss: 0.722354  [25600/60000]\n",
      "loss: 0.726126  [32000/60000]\n",
      "loss: 0.814780  [38400/60000]\n",
      "loss: 0.782706  [44800/60000]\n",
      "loss: 0.802274  [51200/60000]\n",
      "loss: 0.757465  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.752473 \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# 进行训练\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epock {t+1}\\n-----------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "torch.save(model.state_dict(),'model/model_weight.pth')\n",
    "# 保存模型的结构\n",
    "torch.save(model, 'model/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.752473 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载模型的参数\n",
    "# 先要定义模型的结构\n",
    "model_pre = NeuralNetwork()\n",
    "model_pre.load_state_dict(torch.load('model/model_weight.pth'))\n",
    "test_loop(test_dataloader, model_pre, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.752473 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 直接加载整个模型包括模型的框架和参数\n",
    "model_all = torch.load('model/model.pth')\n",
    "test_loop(test_dataloader, model_all, loss_fn)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ba52228318ac7a49b387b661d7c5b5da191fb3537bd08c26009413472b57ea6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
