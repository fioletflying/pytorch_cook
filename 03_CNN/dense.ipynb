{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import optim\n",
    "import time\n",
    "import util_fei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_channels, num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
    "        nn.Conv2d(input_channels, num_channels, \n",
    "                    kernel_size=3, padding=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, input_channels, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layer = []\n",
    "        for i in range(num_convs):\n",
    "            layer.append(conv_block(\n",
    "                num_channels * i + input_channels, num_channels))\n",
    "        self.net = nn.Sequential(*layer)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            X = torch.cat((X, Y), dim=1)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "blk = DenseBlock(2, 3, 10)\n",
    "X = torch.randn(4, 3, 8, 8)\n",
    "Y = blk(X)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(input_channels, num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(input_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(input_channels, num_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "blk = transition_block(23, 10)\n",
    "print(blk(Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet 模型\n",
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels, growth_rate = 64, 32\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
    "blks = []\n",
    "\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    blks.append(DenseBlock(num_convs, num_channels, growth_rate))\n",
    "\n",
    "    num_channels += num_convs * growth_rate\n",
    "\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\n",
    "        blks.append(transition_block(num_channels, num_channels // 2))\n",
    "        num_channels = num_channels // 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    b1,\n",
    "    *blks,\n",
    "    nn.BatchNorm2d(num_channels),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d((1,1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(num_channels, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform= transforms.Compose([transforms.Resize(96),\n",
    "                                transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(96),\n",
    "        transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/study/git/pytorch_cook/03_CNN/util_fei.py:26: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1,\t                train_loss: 0.525589,\t                train_correct:0.813600,\t                test_correct:0.829200,\t                test time:31.063614\n",
      "epoch: 2,\t                train_loss: 0.304202,\t                train_correct:0.889333,\t                test_correct:0.852500,\t                test time:27.301594\n",
      "epoch: 3,\t                train_loss: 0.253136,\t                train_correct:0.907800,\t                test_correct:0.883700,\t                test time:27.234114\n",
      "epoch: 4,\t                train_loss: 0.221616,\t                train_correct:0.919167,\t                test_correct:0.854800,\t                test time:27.304331\n",
      "epoch: 5,\t                train_loss: 0.198567,\t                train_correct:0.927883,\t                test_correct:0.875300,\t                test time:27.261773\n",
      "epoch: 6,\t                train_loss: 0.178641,\t                train_correct:0.934850,\t                test_correct:0.883100,\t                test time:27.329575\n",
      "epoch: 7,\t                train_loss: 0.163068,\t                train_correct:0.940200,\t                test_correct:0.896200,\t                test time:27.241592\n",
      "epoch: 8,\t                train_loss: 0.148629,\t                train_correct:0.946783,\t                test_correct:0.899400,\t                test time:27.242098\n",
      "epoch: 9,\t                train_loss: 0.134339,\t                train_correct:0.952433,\t                test_correct:0.899300,\t                test time:27.357601\n",
      "epoch: 10,\t                train_loss: 0.121612,\t                train_correct:0.957400,\t                test_correct:0.894600,\t                test time:27.235603\n"
     ]
    }
   ],
   "source": [
    "creterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "epoch_nums = 10\n",
    "\n",
    "util_fei.train_model(net, train_dataloader, test_dataloader,creterion, optimizer,device, epoch_num=epoch_nums)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
